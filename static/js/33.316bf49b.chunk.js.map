{"version":3,"file":"static/js/33.316bf49b.chunk.js","mappings":"6TAIaA,EAAkB,oBAAAA,KAAAC,EAAAA,EAAAA,GAAA,KAAAD,EAAA,CAW1B,OAX0BE,EAAAA,EAAAA,GAAAF,EAAA,EAAAG,IAAA,iBAAAC,MAC3B,eAAAC,GAAAC,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MAOA,SAAAC,EAAqBC,EAAKC,GAAO,IAAAC,EAAAC,EAAA,OAAAN,EAAAA,EAAAA,KAAAO,MAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,OACK,OAA5BJ,EAASK,KAAKC,UAAUT,GAAIK,EAAAK,OAAA,SAC3BP,EAAOQ,QAAiC,QAA1BT,EAAQ,OAAPD,QAAO,IAAPA,OAAO,EAAPA,EAASW,wBAAgB,IAAAV,EAAAA,EAAI,CAAC,IAAE,wBAAAG,EAAAQ,OAAA,GAAAd,EAAA,UACzD,gBAAAe,EAAAC,GAAA,OAAApB,EAAAqB,MAAA,KAAAC,UAAA,EAVD,MAUC3B,CAAA,CAX0B,GAkBlB4B,EAAyB,SAAAC,IAAAC,EAAAA,EAAAA,GAAAF,EAAAC,GAAA,IAAAE,GAAAC,EAAAA,EAAAA,GAAAJ,GAClC,SAAAA,EAAYK,GAAmC,IAAAC,EAAnBC,EAAYR,UAAAS,OAAA,QAAAC,IAAAV,UAAA,GAAAA,UAAA,GAAG,GAeN,OAfQ1B,EAAAA,EAAAA,GAAA,KAAA2B,GACzCM,EAAAH,EAAAO,KAAA,MACAC,OAAOC,gBAAcC,EAAAA,EAAAA,GAAAP,GAAO,gBAAiB,CACzCQ,YAAY,EACZC,cAAc,EACdC,UAAU,EACVxC,WAAO,IAEXmC,OAAOC,gBAAcC,EAAAA,EAAAA,GAAAP,GAAO,eAAgB,CACxCQ,YAAY,EACZC,cAAc,EACdC,UAAU,EACVxC,WAAO,IAEX8B,EAAKW,cAAgBZ,EACrBC,EAAKC,aAAeA,EAAaD,CACrC,CAcC,OAbDhC,EAAAA,EAAAA,GAAA0B,EAAA,EAAAzB,IAAA,YAAAC,MAMA,SAAUM,GAAK,IACwCoC,EADxCC,GAAAC,EAAAA,EAAAA,GACuB9B,KAAKiB,cAAY,IAAnD,IAAAY,EAAAE,MAAAH,EAAAC,EAAAG,KAAAC,MAAqD,KAAAC,GAAAC,EAAAA,EAAAA,GAAAP,EAAA1C,MAAA,GAAzCkD,EAASF,EAAA,GAAEvC,EAAMuC,EAAA,GACzB,GAAIE,EAAU5C,GACV,OAAOG,CAEf,CAAC,OAAA0C,GAAAR,EAAAS,EAAAD,EAAA,SAAAR,EAAAU,GAAA,CACD,OAAOvC,KAAK2B,aAChB,KAACjB,CAAA,CA/BiC,CAAS5B,GA4CxC,SAAS0D,EAAYhD,GACxB,MAA4B,oBAArBA,EAAIiD,YACf,CChCO,ICjCMC,EAAkC,IAAIC,EAAAA,GAAe,CAC9DC,SAAU,2NACVC,eAAgB,CAAC,UAAW,cAM1BC,EAAW,CACCC,EAAAA,GAAAA,aALM,gMAMNC,EAAAA,GAAAA,aAAwC,eAG7CC,EAAmC,IAAIvC,EAA0BgC,EAAmB,CAAC,CAACF,EADjEU,EAAAA,GAAAA,aAAgCJ,MCU3D,SAASK,EAAiB3D,GAAkB,IAAb4D,EAAM3C,UAAAS,OAAA,QAAAC,IAAAV,UAAA,GAAAA,UAAA,GAAG,CAAC,EAC5C4C,EAAgED,EAAxDzD,OAAAA,OAAM,IAAA0D,EAAGJ,EAAmBhD,UAAUT,GAAI6D,EAAEC,EAAYF,EAAZE,QAC9CC,EAAW,IAAIC,EAAAA,SAAS,CAAE7D,OAAAA,EAAQH,IAAAA,EAAK8D,QAAAA,IAE7C,OADc,IAAIG,EAAAA,oBAAoB,CAAEF,SAAAA,EAAUD,QAAAA,GAEtD,CClBO,IAAMI,EAAe,SAAAC,IAAA/C,EAAAA,EAAAA,GAAA8C,EAAAC,GAAA,IAAA9C,GAAAC,EAAAA,EAAAA,GAAA4C,GAUxB,SAAAA,EAAYE,GAAQ,IAAAC,EAAAC,EAAAC,EAAA/C,EAqC+C,OArC/CjC,EAAAA,EAAAA,GAAA,KAAA2E,GAChB1C,EAAAH,EAAAO,KAAA,KAAMwC,GACNvC,OAAOC,gBAAcC,EAAAA,EAAAA,GAAAP,GAAO,IAAK,CAC7BQ,YAAY,EACZC,cAAc,EACdC,UAAU,EACVxC,MAAO,IAEXmC,OAAOC,gBAAcC,EAAAA,EAAAA,GAAAP,GAAO,WAAY,CACpCQ,YAAY,EACZC,cAAc,EACdC,UAAU,EACVxC,MAAO,UAEXmC,OAAOC,gBAAcC,EAAAA,EAAAA,GAAAP,GAAO,cAAe,CACvCQ,YAAY,EACZC,cAAc,EACdC,UAAU,EACVxC,WAAO,IAEXmC,OAAOC,gBAAcC,EAAAA,EAAAA,GAAAP,GAAO,wBAAyB,CACjDQ,YAAY,EACZC,cAAc,EACdC,UAAU,EACVxC,WAAO,IAEXmC,OAAOC,gBAAcC,EAAAA,EAAAA,GAAAP,GAAO,wBAAyB,CACjDQ,YAAY,EACZC,cAAc,EACdC,UAAU,EACVxC,OAAO,IAEX8B,EAAKgD,YAAcJ,EAAOI,YAC1BhD,EAAKiD,sBAAwBL,EAAOK,sBACpCjD,EAAKkD,SAA0B,QAAlBL,EAAGD,EAAOM,gBAAQ,IAAAL,EAAAA,EAAI7C,EAAKkD,SACxClD,EAAKmD,EAAY,QAAXL,EAAGF,EAAOO,SAAC,IAAAL,EAAAA,EAAI9C,EAAKmD,EAC1BnD,EAAKoD,sBAC2B,QADNL,EACtBH,EAAOQ,6BAAqB,IAAAL,EAAAA,EAAI/C,EAAKoD,sBAAsBpD,CACnE,CA0DC,OAzDDhC,EAAAA,EAAAA,GAAA0E,EAAA,EAAAzE,IAAA,YAAAoF,IA7CA,WACI,MAAO,CAACrE,KAAKkE,SACjB,GAAC,CAAAjF,IAAA,aAAAoF,IACD,WACI,OAAOrE,KAAKiE,sBAAsBK,WAAWC,OAAOvE,KAAKoE,sBAAwB,CAAC,mBAAqB,GAC3G,GAAC,CAAAnF,IAAA,QAAAC,MAAA,eAAAsF,GAAApF,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MAyCD,SAAAC,EAAYkF,EAAQC,GAAU,IAAAC,EAAAC,EAAAC,EAAAC,EAAA,OAAAzF,EAAAA,EAAAA,KAAAO,MAAA,SAAAC,GAAA,cAAAA,EAAAC,KAAAD,EAAAE,MAAA,UACpBC,KAAKkE,YAAYO,EAAM,CAAA5E,EAAAE,KAAA,cACnB,IAAIgF,MAAM,gBAADR,OAAiBvE,KAAKkE,SAAQ,gBAAc,OAEzB,OAAhCS,EAAWF,EAAOzE,KAAKkE,UAASrE,EAAAE,KAAA,EACnBC,KAAKgE,YAAYgB,iBAAiBL,EAAU3E,KAAKmE,EAAGM,EAAOQ,OAAkB,OAAVP,QAAU,IAAVA,OAAU,EAAVA,EAAYQ,SAAS,gBAAe,OACxE,OAD5CN,EAAI/E,EAAAsF,KACJN,EAAS,CAAEF,SAAAA,EAAUS,gBAAiBR,GAAM/E,EAAAE,KAAA,EAC7BC,KAAKiE,sBAAsB7C,KAAKyD,EAAkB,OAAVH,QAAU,IAAVA,OAAU,EAAVA,EAAYQ,SAAS,sBAAqB,OAA3F,GAANJ,EAAMjF,EAAAsF,MACRnF,KAAKoE,sBAAuB,CAAFvE,EAAAE,KAAA,gBAAAF,EAAAK,OAAA,UAAAmF,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,GAAA,GAEnBP,GAAM,IACTQ,gBAAiBV,KAAI,eAAA/E,EAAAK,OAAA,SAGtB4E,GAAM,yBAAAjF,EAAAQ,OAAA,GAAAd,EAAA,UAChB,gBAAAe,EAAAC,GAAA,OAAAiE,EAAAhE,MAAA,KAAAC,UAAA,EAxDA,IAwDA,CAAAxB,IAAA,aAAAC,MACD,WACI,MAAO,cACX,GAAC,CAAAD,IAAA,YAAAC,MAeD,WACI,MAAO,CACHqG,MAAOvF,KAAKwF,aACZC,wBAAyBzF,KAAKiE,sBAAsByB,YACpDvB,EAAGnE,KAAKmE,EAEhB,IACA,EAAAlF,IAAA,UAAAC,MAzFA,WACI,MAAO,iBACX,GAAC,CAAAD,IAAA,cAAAC,MAAA,eAAAyG,GAAAvG,EAAAA,EAAAA,IAAAC,EAAAA,EAAAA,KAAAC,MAkED,SAAAsG,EAAyBC,EAAMpB,GAAM,IAAAT,EAAA,OAAA3E,EAAAA,EAAAA,KAAAO,MAAA,SAAAkG,GAAA,cAAAA,EAAAhG,KAAAgG,EAAA/F,MAAA,UAC3B,gBAAiB0E,EAAM,CAAAqB,EAAA/F,KAAA,cACnB,IAAIgF,MAAM,gEAA+D,OAEhE,GAAXf,EAAgBS,EAAhBT,YACH6B,EAAKJ,wBAAyB,CAAFK,EAAA/F,KAAA,cACvB,IAAIgF,MAAM,wEAAuE,OAEjE,OAFiEe,EAAAC,GAEhFrC,EAAeoC,EAAA/F,KAAA,EACOiG,EAAAA,EAAAA,YAAsBH,EAAKJ,yBAAwB,OAErE,OAFqEK,EAAAG,GAAAH,EAAAX,KAAAW,EAAAI,GAC7EL,EAAK1B,EAAC2B,EAAAK,GACTnC,EAAW8B,EAAAM,GAAA,CAFXnC,sBAAqB6B,EAAAG,GACrB9B,EAAC2B,EAAAI,GACDlC,YAAW8B,EAAAK,IAAAL,EAAA5F,OAAA,aAAA4F,EAAAC,GAAAD,EAAAM,KAAA,yBAAAN,EAAAzF,OAAA,GAAAuF,EAAA,KAElB,gBAAAS,EAAAC,GAAA,OAAAX,EAAAnF,MAAA,KAAAC,UAAA,EA/EA,IA+EA,CAAAxB,IAAA,UAAAC,MAiBD,SAAeM,EAAKwE,EAAavE,GAC7B,IAAM8G,EAAUpD,EAAiB3D,GACjC,OAAO,IAAIQ,MAAIqF,EAAAA,EAAAA,GAAC,CACZrB,YAAAA,EACAC,sBAAuBsC,GACpB9G,GAEX,KAACiE,CAAA,CA1GuB,CAASsC,EAAAA,E","sources":["../node_modules/@langchain/core/dist/example_selectors/conditional.js","../node_modules/@langchain/core/dist/example_selectors/semantic_similarity.js","../node_modules/langchain/dist/chains/question_answering/stuff_prompts.js","../node_modules/langchain/dist/chains/question_answering/load.js","../node_modules/langchain/dist/chains/vector_db_qa.js"],"sourcesContent":["/**\n * Abstract class that defines the interface for selecting a prompt for a\n * given language model.\n */\nexport class BasePromptSelector {\n    /**\n     * Asynchronous version of `getPrompt` that also accepts an options object\n     * for partial variables.\n     * @param llm The language model for which to get a prompt.\n     * @param options Optional object for partial variables.\n     * @returns A Promise that resolves to a prompt template.\n     */\n    async getPromptAsync(llm, options) {\n        const prompt = this.getPrompt(llm);\n        return prompt.partial(options?.partialVariables ?? {});\n    }\n}\n/**\n * Concrete implementation of `BasePromptSelector` that selects a prompt\n * based on a set of conditions. It has a default prompt that it returns\n * if none of the conditions are met.\n */\nexport class ConditionalPromptSelector extends BasePromptSelector {\n    constructor(default_prompt, conditionals = []) {\n        super();\n        Object.defineProperty(this, \"defaultPrompt\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"conditionals\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.defaultPrompt = default_prompt;\n        this.conditionals = conditionals;\n    }\n    /**\n     * Method that selects a prompt based on a set of conditions. If none of\n     * the conditions are met, it returns the default prompt.\n     * @param llm The language model for which to get a prompt.\n     * @returns A prompt template.\n     */\n    getPrompt(llm) {\n        for (const [condition, prompt] of this.conditionals) {\n            if (condition(llm)) {\n                return prompt;\n            }\n        }\n        return this.defaultPrompt;\n    }\n}\n/**\n * Type guard function that checks if a given language model is of type\n * `BaseLLM`.\n */\nexport function isLLM(llm) {\n    return llm._modelType() === \"base_llm\";\n}\n/**\n * Type guard function that checks if a given language model is of type\n * `BaseChatModel`.\n */\nexport function isChatModel(llm) {\n    return llm._modelType() === \"base_chat_model\";\n}\n","import { Document } from \"../documents/document.js\";\nimport { BaseExampleSelector } from \"./base.js\";\nfunction sortedValues(values) {\n    return Object.keys(values)\n        .sort()\n        .map((key) => values[key]);\n}\n/**\n * Class that selects examples based on semantic similarity. It extends\n * the BaseExampleSelector class.\n * @example\n * ```typescript\n * const exampleSelector = await SemanticSimilarityExampleSelector.fromExamples(\n *   [\n *     { input: \"happy\", output: \"sad\" },\n *     { input: \"tall\", output: \"short\" },\n *     { input: \"energetic\", output: \"lethargic\" },\n *     { input: \"sunny\", output: \"gloomy\" },\n *     { input: \"windy\", output: \"calm\" },\n *   ],\n *   new OpenAIEmbeddings(),\n *   HNSWLib,\n *   { k: 1 },\n * );\n * const dynamicPrompt = new FewShotPromptTemplate({\n *   exampleSelector,\n *   examplePrompt: PromptTemplate.fromTemplate(\n *     \"Input: {input}\\nOutput: {output}\",\n *   ),\n *   prefix: \"Give the antonym of every input\",\n *   suffix: \"Input: {adjective}\\nOutput:\",\n *   inputVariables: [\"adjective\"],\n * });\n * console.log(await dynamicPrompt.format({ adjective: \"rainy\" }));\n * ```\n */\nexport class SemanticSimilarityExampleSelector extends BaseExampleSelector {\n    constructor(data) {\n        super(data);\n        Object.defineProperty(this, \"vectorStoreRetriever\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"exampleKeys\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"inputKeys\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.exampleKeys = data.exampleKeys;\n        this.inputKeys = data.inputKeys;\n        if (data.vectorStore !== undefined) {\n            this.vectorStoreRetriever = data.vectorStore.asRetriever({\n                k: data.k ?? 4,\n                filter: data.filter,\n            });\n        }\n        else if (data.vectorStoreRetriever) {\n            this.vectorStoreRetriever = data.vectorStoreRetriever;\n        }\n        else {\n            throw new Error(`You must specify one of \"vectorStore\" and \"vectorStoreRetriever\".`);\n        }\n    }\n    /**\n     * Method that adds a new example to the vectorStore. The example is\n     * converted to a string and added to the vectorStore as a document.\n     * @param example The example to be added to the vectorStore.\n     * @returns Promise that resolves when the example has been added to the vectorStore.\n     */\n    async addExample(example) {\n        const inputKeys = this.inputKeys ?? Object.keys(example);\n        const stringExample = sortedValues(inputKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {})).join(\" \");\n        await this.vectorStoreRetriever.addDocuments([\n            new Document({\n                pageContent: stringExample,\n                metadata: example,\n            }),\n        ]);\n    }\n    /**\n     * Method that selects which examples to use based on semantic similarity.\n     * It performs a similarity search in the vectorStore using the input\n     * variables and returns the examples with the highest similarity.\n     * @param inputVariables The input variables used for the similarity search.\n     * @returns Promise that resolves with an array of the selected examples.\n     */\n    async selectExamples(inputVariables) {\n        const inputKeys = this.inputKeys ?? Object.keys(inputVariables);\n        const query = sortedValues(inputKeys.reduce((acc, key) => ({ ...acc, [key]: inputVariables[key] }), {})).join(\" \");\n        const exampleDocs = await this.vectorStoreRetriever.invoke(query);\n        const examples = exampleDocs.map((doc) => doc.metadata);\n        if (this.exampleKeys) {\n            // If example keys are provided, filter examples to those keys.\n            return examples.map((example) => this.exampleKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {}));\n        }\n        return examples;\n    }\n    /**\n     * Static method that creates a new instance of\n     * SemanticSimilarityExampleSelector. It takes a list of examples, an\n     * instance of Embeddings, a VectorStore class, and an options object as\n     * parameters. It converts the examples to strings, creates a VectorStore\n     * from the strings and the embeddings, and returns a new\n     * SemanticSimilarityExampleSelector with the created VectorStore and the\n     * options provided.\n     * @param examples The list of examples to be used.\n     * @param embeddings The instance of Embeddings to be used.\n     * @param vectorStoreCls The VectorStore class to be used.\n     * @param options The options object for the SemanticSimilarityExampleSelector.\n     * @returns Promise that resolves with a new instance of SemanticSimilarityExampleSelector.\n     */\n    static async fromExamples(examples, embeddings, vectorStoreCls, options = {}) {\n        const inputKeys = options.inputKeys ?? null;\n        const stringExamples = examples.map((example) => sortedValues(inputKeys\n            ? inputKeys.reduce((acc, key) => ({ ...acc, [key]: example[key] }), {})\n            : example).join(\" \"));\n        const vectorStore = await vectorStoreCls.fromTexts(stringExamples, examples, // metadatas\n        embeddings, options);\n        return new SemanticSimilarityExampleSelector({\n            vectorStore,\n            k: options.k ?? 4,\n            exampleKeys: options.exampleKeys,\n            inputKeys: options.inputKeys,\n        });\n    }\n}\n","/* eslint-disable spaced-comment */\nimport { ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate, } from \"@langchain/core/prompts\";\nimport { ConditionalPromptSelector, isChatModel, } from \"@langchain/core/example_selectors\";\nexport const DEFAULT_QA_PROMPT = /*#__PURE__*/ new PromptTemplate({\n    template: \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\",\n    inputVariables: [\"context\", \"question\"],\n});\nconst system_template = `Use the following pieces of context to answer the users question. \nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n----------------\n{context}`;\nconst messages = [\n    /*#__PURE__*/ SystemMessagePromptTemplate.fromTemplate(system_template),\n    /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(\"{question}\"),\n];\nconst CHAT_PROMPT = /*#__PURE__*/ ChatPromptTemplate.fromMessages(messages);\nexport const QA_PROMPT_SELECTOR = /*#__PURE__*/ new ConditionalPromptSelector(DEFAULT_QA_PROMPT, [[isChatModel, CHAT_PROMPT]]);\n","import { LLMChain } from \"../llm_chain.js\";\nimport { StuffDocumentsChain, MapReduceDocumentsChain, RefineDocumentsChain, } from \"../combine_docs_chain.js\";\nimport { QA_PROMPT_SELECTOR } from \"./stuff_prompts.js\";\nimport { COMBINE_PROMPT_SELECTOR, COMBINE_QA_PROMPT_SELECTOR, } from \"./map_reduce_prompts.js\";\nimport { QUESTION_PROMPT_SELECTOR, REFINE_PROMPT_SELECTOR, } from \"./refine_prompts.js\";\nexport const loadQAChain = (llm, params = { type: \"stuff\" }) => {\n    const { type } = params;\n    if (type === \"stuff\") {\n        return loadQAStuffChain(llm, params);\n    }\n    if (type === \"map_reduce\") {\n        return loadQAMapReduceChain(llm, params);\n    }\n    if (type === \"refine\") {\n        return loadQARefineChain(llm, params);\n    }\n    throw new Error(`Invalid _type: ${type}`);\n};\n/**\n * Loads a StuffQAChain based on the provided parameters. It takes an LLM\n * instance and StuffQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a StuffQAChain.\n * @returns A StuffQAChain instance.\n */\nexport function loadQAStuffChain(llm, params = {}) {\n    const { prompt = QA_PROMPT_SELECTOR.getPrompt(llm), verbose } = params;\n    const llmChain = new LLMChain({ prompt, llm, verbose });\n    const chain = new StuffDocumentsChain({ llmChain, verbose });\n    return chain;\n}\n/**\n * Loads a MapReduceQAChain based on the provided parameters. It takes an\n * LLM instance and MapReduceQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a MapReduceQAChain.\n * @returns A MapReduceQAChain instance.\n */\nexport function loadQAMapReduceChain(llm, params = {}) {\n    const { combineMapPrompt = COMBINE_QA_PROMPT_SELECTOR.getPrompt(llm), combinePrompt = COMBINE_PROMPT_SELECTOR.getPrompt(llm), verbose, combineLLM, returnIntermediateSteps, } = params;\n    const llmChain = new LLMChain({ prompt: combineMapPrompt, llm, verbose });\n    const combineLLMChain = new LLMChain({\n        prompt: combinePrompt,\n        llm: combineLLM ?? llm,\n        verbose,\n    });\n    const combineDocumentChain = new StuffDocumentsChain({\n        llmChain: combineLLMChain,\n        documentVariableName: \"summaries\",\n        verbose,\n    });\n    const chain = new MapReduceDocumentsChain({\n        llmChain,\n        combineDocumentChain,\n        returnIntermediateSteps,\n        verbose,\n    });\n    return chain;\n}\n/**\n * Loads a RefineQAChain based on the provided parameters. It takes an LLM\n * instance and RefineQAChainParams as parameters.\n * @param llm An instance of BaseLanguageModel.\n * @param params Parameters for creating a RefineQAChain.\n * @returns A RefineQAChain instance.\n */\nexport function loadQARefineChain(llm, params = {}) {\n    const { questionPrompt = QUESTION_PROMPT_SELECTOR.getPrompt(llm), refinePrompt = REFINE_PROMPT_SELECTOR.getPrompt(llm), refineLLM, verbose, } = params;\n    const llmChain = new LLMChain({ prompt: questionPrompt, llm, verbose });\n    const refineLLMChain = new LLMChain({\n        prompt: refinePrompt,\n        llm: refineLLM ?? llm,\n        verbose,\n    });\n    const chain = new RefineDocumentsChain({\n        llmChain,\n        refineLLMChain,\n        verbose,\n    });\n    return chain;\n}\n","import { BaseChain } from \"./base.js\";\nimport { loadQAStuffChain } from \"./question_answering/load.js\";\n/**\n * Class that represents a VectorDBQAChain. It extends the `BaseChain`\n * class and implements the `VectorDBQAChainInput` interface. It performs\n * a similarity search using a vector store and combines the search\n * results using a specified combine documents chain.\n *\n * @deprecated\n * Switch to {@link https://js.langchain.com/docs/modules/chains/ | createRetrievalChain}\n * Will be removed in 0.2.0\n */\nexport class VectorDBQAChain extends BaseChain {\n    static lc_name() {\n        return \"VectorDBQAChain\";\n    }\n    get inputKeys() {\n        return [this.inputKey];\n    }\n    get outputKeys() {\n        return this.combineDocumentsChain.outputKeys.concat(this.returnSourceDocuments ? [\"sourceDocuments\"] : []);\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"k\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 4\n        });\n        Object.defineProperty(this, \"inputKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"query\"\n        });\n        Object.defineProperty(this, \"vectorstore\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"combineDocumentsChain\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"returnSourceDocuments\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        this.vectorstore = fields.vectorstore;\n        this.combineDocumentsChain = fields.combineDocumentsChain;\n        this.inputKey = fields.inputKey ?? this.inputKey;\n        this.k = fields.k ?? this.k;\n        this.returnSourceDocuments =\n            fields.returnSourceDocuments ?? this.returnSourceDocuments;\n    }\n    /** @ignore */\n    async _call(values, runManager) {\n        if (!(this.inputKey in values)) {\n            throw new Error(`Question key ${this.inputKey} not found.`);\n        }\n        const question = values[this.inputKey];\n        const docs = await this.vectorstore.similaritySearch(question, this.k, values.filter, runManager?.getChild(\"vectorstore\"));\n        const inputs = { question, input_documents: docs };\n        const result = await this.combineDocumentsChain.call(inputs, runManager?.getChild(\"combine_documents\"));\n        if (this.returnSourceDocuments) {\n            return {\n                ...result,\n                sourceDocuments: docs,\n            };\n        }\n        return result;\n    }\n    _chainType() {\n        return \"vector_db_qa\";\n    }\n    static async deserialize(data, values) {\n        if (!(\"vectorstore\" in values)) {\n            throw new Error(`Need to pass in a vectorstore to deserialize VectorDBQAChain`);\n        }\n        const { vectorstore } = values;\n        if (!data.combine_documents_chain) {\n            throw new Error(`VectorDBQAChain must have combine_documents_chain in serialized data`);\n        }\n        return new VectorDBQAChain({\n            combineDocumentsChain: await BaseChain.deserialize(data.combine_documents_chain),\n            k: data.k,\n            vectorstore,\n        });\n    }\n    serialize() {\n        return {\n            _type: this._chainType(),\n            combine_documents_chain: this.combineDocumentsChain.serialize(),\n            k: this.k,\n        };\n    }\n    /**\n     * Static method that creates a VectorDBQAChain instance from a\n     * BaseLanguageModel and a vector store. It also accepts optional options\n     * to customize the chain.\n     * @param llm The BaseLanguageModel instance.\n     * @param vectorstore The vector store used for similarity search.\n     * @param options Optional options to customize the chain.\n     * @returns A new instance of VectorDBQAChain.\n     */\n    static fromLLM(llm, vectorstore, options) {\n        const qaChain = loadQAStuffChain(llm);\n        return new this({\n            vectorstore,\n            combineDocumentsChain: qaChain,\n            ...options,\n        });\n    }\n}\n"],"names":["BasePromptSelector","_classCallCheck","_createClass","key","value","_getPromptAsync","_asyncToGenerator","_regeneratorRuntime","mark","_callee","llm","options","_options$partialVaria","prompt","wrap","_context","prev","next","this","getPrompt","abrupt","partial","partialVariables","stop","_x","_x2","apply","arguments","ConditionalPromptSelector","_BasePromptSelector","_inherits","_super","_createSuper","default_prompt","_this","conditionals","length","undefined","call","Object","defineProperty","_assertThisInitialized","enumerable","configurable","writable","defaultPrompt","_step","_iterator","_createForOfIteratorHelper","s","n","done","_step$value","_slicedToArray","condition","err","e","f","isChatModel","_modelType","DEFAULT_QA_PROMPT","PromptTemplate","template","inputVariables","messages","SystemMessagePromptTemplate","HumanMessagePromptTemplate","QA_PROMPT_SELECTOR","ChatPromptTemplate","loadQAStuffChain","params","_params$prompt","verbose","llmChain","LLMChain","StuffDocumentsChain","VectorDBQAChain","_BaseChain","fields","_fields$inputKey","_fields$k","_fields$returnSourceD","vectorstore","combineDocumentsChain","inputKey","k","returnSourceDocuments","get","outputKeys","concat","_call2","values","runManager","question","docs","inputs","result","Error","similaritySearch","filter","getChild","sent","input_documents","_objectSpread","sourceDocuments","_type","_chainType","combine_documents_chain","serialize","_deserialize","_callee2","data","_context2","t0","BaseChain","t1","t2","t3","t4","_x3","_x4","qaChain"],"sourceRoot":""}